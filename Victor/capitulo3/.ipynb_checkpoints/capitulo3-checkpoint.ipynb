{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se lee un ejemplo de ham e imprime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: mcmullen gas for 11 / 99\n",
      "jackie ,\n",
      "since the inlet to 3 river plant is shut in on 10 / 19 / 99 ( the last day of\n",
      "flow ) :\n",
      "at what meter is the mcmullen gas being diverted to ?\n",
      "at what meter is hpl buying the residue gas ? ( this is the gas from teco ,\n",
      "vastar , vintage , tejones , and swift )\n",
      "i still see active deals at meter 3405 in path manager for teco , vastar ,\n",
      "vintage , tejones , and swift\n",
      "i also see gas scheduled in pops at meter 3404 and 3405 .\n",
      "please advice . we need to resolve this as soon as possible so settlement\n",
      "can send out payments .\n",
      "thanks\n"
     ]
    }
   ],
   "source": [
    "file_path = 'enron1/ham/0007.1999-12-14.farmer.ham.txt'\n",
    "with open(file_path, 'r') as infile:\n",
    "    ham_sample = infile.read()\n",
    "print(ham_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se lee un ejemplo de spam e imprime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: stacey automated system generating 8 k per week parallelogram\n",
      "people are\n",
      "getting rich using this system ! now it ' s your\n",
      "turn !\n",
      "we ' ve\n",
      "cracked the code and will show you . . . .\n",
      "this is the\n",
      "only system that does everything for you , so you can make\n",
      "money\n",
      ". . . . . . . .\n",
      "because your\n",
      "success is . . . completely automated !\n",
      "let me show\n",
      "you how !\n",
      "click\n",
      "here\n",
      "to opt out click here % random _ text\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = 'enron1/spam/0058.2003-12-21.GP.spam.txt'\n",
    "with open(file_path, 'r') as infile:\n",
    "    spam_sample = infile.read()\n",
    "print(spam_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se leeen los archivos\n",
    "Se lee cada uno de los archivos que existen en spam y se almacenan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np \n",
    "\n",
    "emails, labels = [], []\n",
    "\n",
    "file_path = 'enron1/spam/'\n",
    "for filename in glob.glob(os.path.join(file_path, '*.txt')):\n",
    "    with open(filename, 'r', encoding = \"ISO-8859-1\") as infile:\n",
    "        emails.append(infile.read())\n",
    "        labels.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Se lee cada uno de los archivos que existen en ham y se almacenan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'enron1/ham/'\n",
    "for filename in glob.glob(os.path.join(file_path, '*.txt')):\n",
    "    with open(filename, 'r', encoding = \"ISO-8859-1\") as infile:\n",
    "        emails.append(infile.read())\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5172"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emails)\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se remuven signos de puntuación y stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def letters_only(astr):\n",
    "    return astr.isalpha()\n",
    "\n",
    "\n",
    "all_names = set(names.words())\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def clean_text(docs):\n",
    "    cleaned_docs = []\n",
    "    for doc in docs:\n",
    "        cleaned_docs.append(' '.join([lemmatizer.lemmatize(word.lower())\n",
    "                                        for word in doc.split()\n",
    "                                        if letters_only(word)\n",
    "                                        and word not in all_names]))\n",
    "    return cleaned_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'approval hello we sent you an email a while ago because you now qualify for a new mortgage you could get for a little a a month bad credit is no problem you can pull cash out or refinance please click on this link for free consultation by a mortgage broker start saving here best regard alejandra stern libreville juniper accord cervix ember freest episcopal kink agent buxom audiotape rand taurus tara thither butchery extraneous blatzcleat gaston stratosphere milky builtin do druid causation headquarter worktable glycerin despondent clipboard illegible controversy fail result routautonomy cloture withdrew crab hermetic trench befogging closure strongroom thurman batchelder sylvan depository beautiful suppressor sea houston blouse cup waffle felony chit thank maltose command frustrate arty empower habib margery scam jo farthest wilburmarc edgewise allah grumble consequential josiah avoid bloomington ubiquity cityscape bookcase amherst business bias matte'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_emails = clean_text(emails)\n",
    "cleaned_emails[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizar palabras\n",
    "Se convierte en un vector unicamente con las 500 palabras que mas se repitan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words=\"english\", max_features=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 390)\t1\n",
      "  (0, 121)\t1\n",
      "  (0, 285)\t1\n",
      "  (0, 242)\t1\n",
      "  (0, 276)\t1\n",
      "  (0, 341)\t1\n",
      "  (0, 66)\t1\n",
      "  (0, 239)\t1\n",
      "  (0, 158)\t1\n",
      "  (0, 409)\t1\n",
      "  (0, 36)\t1\n",
      "  (0, 362)\t1\n",
      "  (0, 370)\t1\n",
      "  (0, 188)\t1\n",
      "  (0, 437)\t1\n",
      "  (0, 44)\t1\n"
     ]
    }
   ],
   "source": [
    "term_docs = cv.fit_transform(cleaned_emails)\n",
    "print(term_docs [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Palabras con reeticiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'energy'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = cv.get_feature_names()\n",
    "feature_names[481]\n",
    "feature_names[357]\n",
    "feature_names[125]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mapping = cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_index(labels):\n",
    "    from collections import defaultdict\n",
    "    label_index = defaultdict(list)\n",
    "    for index, label in enumerate(labels):\n",
    "        label_index[label].append(index)\n",
    "    return label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index = get_label_index(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_prior(label_index):\n",
    "    \"\"\" Compute prior based on training samples\n",
    "    Args:\n",
    "        label_index (grouped sample indices by class)\n",
    "    Returns:\n",
    "        dictionary, with class label as key, corresponding prior as the value\n",
    "    \"\"\"\n",
    "    prior = {label: len(index) for label, index in label_index.items()}\n",
    "    total_count = sum(prior.values())\n",
    "    for label in prior:\n",
    "        prior[label] /= float(total_count)\n",
    "    return prior\n",
    "\n",
    "prior = get_prior(label_index)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_likelihood(term_document_matrix, label_index, smoothing=0):\n",
    "    \"\"\" Compute likelihood based on training samples\n",
    "    Args:\n",
    "        term_document_matrix (sparse matrix)\n",
    "        label_index (grouped sample indices by class)\n",
    "        smoothing (integer, additive Laplace smoothing parameter)\n",
    "    Returns:\n",
    "        dictionary, with class as key, corresponding conditional probability P(feature|class) vector as value\n",
    "    \"\"\"\n",
    "    likelihood = {}\n",
    "    for label, index in label_index.items():\n",
    "        likelihood[label] = term_document_matrix[index, :].sum(axis=0) + smoothing\n",
    "        likelihood[label] = np.asarray(likelihood[label])[0]\n",
    "        total_count = likelihood[label].sum()\n",
    "        likelihood[label] = likelihood[label] / float(total_count)\n",
    "    return likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothing = 1\n",
    "likelihood = get_likelihood(term_docs, label_index, smoothing)\n",
    "len(likelihood[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00108581, 0.00095774, 0.00087978, 0.00084637, 0.00010023])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00108997, 0.00141902, 0.00456555, 0.0005347 , 0.00421594])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood[1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able', 'access', 'account', 'accounting', 'act']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_posterior(term_document_matrix, prior, likelihood):\n",
    "    \"\"\" Compute posterior of testing samples, based on prior and likelihood\n",
    "    Args:\n",
    "        term_document_matrix (sparse matrix)\n",
    "        prior (dictionary, with class label as key, corresponding prior as the value)\n",
    "        likelihood (dictionary, with class label as key, corresponding conditional probability vector as value)\n",
    "    Returns:\n",
    "        dictionary, with class label as key, corresponding posterior as value\n",
    "    \"\"\"\n",
    "    num_docs = term_document_matrix.shape[0]\n",
    "    posteriors = []\n",
    "    for i in range(num_docs):\n",
    "        # posterior is proportional to prior * likelihood\n",
    "        # = exp(log(prior * likelihood))\n",
    "        # = exp(log(prior) + log(likelihood))\n",
    "        posterior = {key: np.log(prior_label) for key, prior_label in prior.items()}\n",
    "        for label, likelihood_label in likelihood.items():\n",
    "            term_document_vector = term_document_matrix.getrow(i)\n",
    "            counts = term_document_vector.data\n",
    "            indices = term_document_vector.indices\n",
    "            for count, index in zip(counts, indices):\n",
    "                posterior[label] += np.log(likelihood_label[index]) * count\n",
    "        # exp(-1000):exp(-999) will cause zero division error,\n",
    "        # however it equates to exp(0):exp(1)\n",
    "        min_log_posterior = min(posterior.values())\n",
    "        for label in posterior:\n",
    "            try:\n",
    "                posterior[label] = np.exp(posterior[label] - min_log_posterior)\n",
    "            except:\n",
    "                # if one's log value is excessively large, assign it infinity\n",
    "                posterior[label] = float('inf')\n",
    "        # normalize so that all sums up to 1\n",
    "        sum_posterior = sum(posterior.values())\n",
    "        for label in posterior:\n",
    "            if posterior[label] == float('inf'):\n",
    "                posterior[label] = 1.0\n",
    "            else:\n",
    "                posterior[label] /= sum_posterior\n",
    "        posteriors.append(posterior.copy())\n",
    "    return posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_test = [\n",
    "    '''Subject: flat screens\n",
    "    hello ,\n",
    "    please call or contact regarding the other flat screens requested .\n",
    "    trisha tlapek - eb 3132 b\n",
    "    michael sergeev - eb 3132 a\n",
    "    also the sun blocker that was taken away from eb 3131 a .\n",
    "    trisha should two monitors also michael .\n",
    "    thanks\n",
    "    kevin moore''',\n",
    "    '''Subject: having problems in bed ? we can help !\n",
    "    cialis allows men to enjoy a fully normal sex life without having to plan the sexual act .\n",
    "    if we let things terrify us , life will not be worth living .\n",
    "    brevity is the soul of lingerie .\n",
    "    suspicion always haunts the guilty mind .''',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{1: 0.0032745671008376, 0: 0.9967254328991624}, {1: 0.9999984725538845, 0: 1.5274461154428757e-06}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cleaned_test = clean_text(emails_test)\n",
    "term_docs_test = cv.transform(cleaned_test)\n",
    "posterior = get_posterior(term_docs_test, prior, likelihood)\n",
    "print(posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(cleaned_emails, labels, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1707, 1707)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(Y_train)\n",
    "len(X_test), len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_docs_train = cv.fit_transform(X_train)\n",
    "label_index = get_label_index(Y_train)\n",
    "prior = get_prior(label_index)\n",
    "likelihood = get_likelihood(term_docs_train, label_index, smoothing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/Documentos/Maestria/Cuatrimestre 2/Inteligencia Artifical/carpeta/env/lib/python3.6/site-packages/ipykernel_launcher.py:28: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "term_docs_test = cv.transform(X_test)\n",
    "posterior = get_posterior(term_docs_test, prior, likelihood)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on 1707 testing samples is: 90.8%\n"
     ]
    }
   ],
   "source": [
    "correct = 0.0\n",
    "for pred, actual in zip(posterior, Y_test):\n",
    "    if actual == 1:\n",
    "        if pred[1] >= 0.5:\n",
    "            correct += 1\n",
    "    elif pred[0] > 0.5:\n",
    "        correct += 1\n",
    "\n",
    "print('The accuracy on {0} testing samples is: {1:.1f}%'.format(len(Y_test), correct/len(Y_test)*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implementar desde 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=1.0, fit_prior=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrena el clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(term_docs_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-121-7ae0d7e632cf>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-121-7ae0d7e632cf>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Se obtienen los resultdos\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Se obtienen los resultdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+000, 1.39236011e-026],\n",
       "       [1.00000000e+000, 1.23720860e-017],\n",
       "       [3.30065914e-048, 1.00000000e+000],\n",
       "       [1.00000000e+000, 6.39079016e-019],\n",
       "       [1.00000000e+000, 6.50186709e-134],\n",
       "       [5.12242799e-002, 9.48775720e-001],\n",
       "       [7.94329755e-006, 9.99992057e-001],\n",
       "       [1.00000000e+000, 2.79114149e-014],\n",
       "       [1.00000000e+000, 1.15975887e-056],\n",
       "       [3.27858452e-014, 1.00000000e+000]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_prob = clf.predict_proba(term_docs_test)\n",
    "prediction_prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se precide \"term_docs_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = clf.predict(term_docs_test)\n",
    "prediction[:10]a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eficiencia de multinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy using MultinomialNB is: 90.8%\n"
     ]
    }
   ],
   "source": [
    "accuracy = clf.score(term_docs_test, Y_test)\n",
    "print('The accuracy using MultinomialNB is: {0:.1f}%'.format(accuracy*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medidas de eficiencia\n",
    "Matriz d confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1093,   98],\n",
       "       [  59,  457]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_test, prediction, labels=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otras medidas de eficacia a un modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "precision_score(Y_test, prediction, pos_label=1)\n",
    "recall_score(Y_test, prediction, pos_label=1)\n",
    "f1_score(Y_test, prediction, pos_label=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
