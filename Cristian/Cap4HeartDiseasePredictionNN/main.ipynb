{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de enfermedades del corazón usando redes neuronales\n",
    "\n",
    "En este codigo se tratara de predecir enfermedades del corazon mediante Redes Neuronales. Los pacientes son clasificados de a cuerdo con diversos grados de enfermedad cronica. El dataset utilizaco consta de 303 pacientes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/echartea/python/entronoVirtual/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/echartea/python/entronoVirtual/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/echartea/python/entronoVirtual/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/echartea/python/entronoVirtual/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/echartea/python/entronoVirtual/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/echartea/python/entronoVirtual/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/echartea/python/entronoVirtual/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/echartea/python/entronoVirtual/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/echartea/python/entronoVirtual/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/echartea/python/entronoVirtual/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/echartea/python/entronoVirtual/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/echartea/python/entronoVirtual/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.9 (default, Nov  7 2019, 10:44:02) \n",
      "[GCC 8.3.0]\n",
      "Pandas: 1.0.0\n",
      "Numpy: 1.18.2\n",
      "Sklearn: 0.22.2.post1\n",
      "Matplotlib: 3.1.2\n",
      "Keras: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import keras\n",
    "\n",
    "print ('Python: {}'.format(sys.version))\n",
    "print ('Pandas: {}'.format(pd.__version__))\n",
    "print ('Numpy: {}'.format(np.__version__))\n",
    "print ('Sklearn: {}'.format(sklearn.__version__))\n",
    "print ('Matplotlib: {}'.format(matplotlib.__version__))\n",
    "print ('Keras: {}'.format(keras.__version__))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importacion del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame: (303, 14)\n",
      "age          67\n",
      "sex           1\n",
      "cp            4\n",
      "trestbps    160\n",
      "chol        286\n",
      "fbs           0\n",
      "restecg       2\n",
      "thalach     108\n",
      "exang         1\n",
      "oldpeak     1.5\n",
      "slope         2\n",
      "ca          3.0\n",
      "thal        3.0\n",
      "class         2\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# import the heart disease dataset\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "\n",
    "# the names will be the names of each column in our pandas DataFrame\n",
    "names = ['age',\n",
    "        'sex',\n",
    "        'cp',\n",
    "        'trestbps',\n",
    "        'chol',\n",
    "        'fbs',\n",
    "        'restecg',\n",
    "        'thalach',\n",
    "        'exang',\n",
    "        'oldpeak',\n",
    "        'slope',\n",
    "        'ca',\n",
    "        'thal',\n",
    "        'class']\n",
    "\n",
    "# read the csv\n",
    "cleveland = pd.read_csv(url, names=names)\n",
    "# print the shape of the DataFrame, so we can see how many examples we have\n",
    "print ('Shape of DataFrame: {}'.format(cleveland.shape))\n",
    "print (cleveland.loc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>?</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "280  57.0  1.0  4.0     110.0  335.0  0.0      0.0    143.0    1.0      3.0   \n",
       "281  47.0  1.0  3.0     130.0  253.0  0.0      0.0    179.0    0.0      0.0   \n",
       "282  55.0  0.0  4.0     128.0  205.0  0.0      1.0    130.0    1.0      2.0   \n",
       "283  35.0  1.0  2.0     122.0  192.0  0.0      0.0    174.0    0.0      0.0   \n",
       "284  61.0  1.0  4.0     148.0  203.0  0.0      0.0    161.0    0.0      0.0   \n",
       "285  58.0  1.0  4.0     114.0  318.0  0.0      1.0    140.0    0.0      4.4   \n",
       "286  58.0  0.0  4.0     170.0  225.0  1.0      2.0    146.0    1.0      2.8   \n",
       "287  58.0  1.0  2.0     125.0  220.0  0.0      0.0    144.0    0.0      0.4   \n",
       "288  56.0  1.0  2.0     130.0  221.0  0.0      2.0    163.0    0.0      0.0   \n",
       "289  56.0  1.0  2.0     120.0  240.0  0.0      0.0    169.0    0.0      0.0   \n",
       "290  67.0  1.0  3.0     152.0  212.0  0.0      2.0    150.0    0.0      0.8   \n",
       "291  55.0  0.0  2.0     132.0  342.0  0.0      0.0    166.0    0.0      1.2   \n",
       "292  44.0  1.0  4.0     120.0  169.0  0.0      0.0    144.0    1.0      2.8   \n",
       "293  63.0  1.0  4.0     140.0  187.0  0.0      2.0    144.0    1.0      4.0   \n",
       "294  63.0  0.0  4.0     124.0  197.0  0.0      0.0    136.0    1.0      0.0   \n",
       "295  41.0  1.0  2.0     120.0  157.0  0.0      0.0    182.0    0.0      0.0   \n",
       "296  59.0  1.0  4.0     164.0  176.0  1.0      2.0     90.0    0.0      1.0   \n",
       "297  57.0  0.0  4.0     140.0  241.0  0.0      0.0    123.0    1.0      0.2   \n",
       "298  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
       "299  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "300  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "301  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
       "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  class  \n",
       "280    2.0  1.0  7.0      2  \n",
       "281    1.0  0.0  3.0      0  \n",
       "282    2.0  1.0  7.0      3  \n",
       "283    1.0  0.0  3.0      0  \n",
       "284    1.0  1.0  7.0      2  \n",
       "285    3.0  3.0  6.0      4  \n",
       "286    2.0  2.0  6.0      2  \n",
       "287    2.0    ?  7.0      0  \n",
       "288    1.0  0.0  7.0      0  \n",
       "289    3.0  0.0  3.0      0  \n",
       "290    2.0  0.0  7.0      1  \n",
       "291    1.0  0.0  3.0      0  \n",
       "292    3.0  0.0  6.0      2  \n",
       "293    1.0  2.0  7.0      2  \n",
       "294    2.0  0.0  3.0      1  \n",
       "295    1.0  0.0  3.0      0  \n",
       "296    2.0  2.0  6.0      3  \n",
       "297    2.0  0.0  7.0      1  \n",
       "298    2.0  0.0  7.0      1  \n",
       "299    2.0  2.0  7.0      2  \n",
       "300    2.0  1.0  7.0      3  \n",
       "301    2.0  1.0  3.0      1  \n",
       "302    1.0    ?  3.0      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the last twenty or so data points\n",
    "cleveland.loc[280:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removemos los datos incompletos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "280  57.0  1.0  4.0     110.0  335.0  0.0      0.0    143.0    1.0      3.0   \n",
       "281  47.0  1.0  3.0     130.0  253.0  0.0      0.0    179.0    0.0      0.0   \n",
       "282  55.0  0.0  4.0     128.0  205.0  0.0      1.0    130.0    1.0      2.0   \n",
       "283  35.0  1.0  2.0     122.0  192.0  0.0      0.0    174.0    0.0      0.0   \n",
       "284  61.0  1.0  4.0     148.0  203.0  0.0      0.0    161.0    0.0      0.0   \n",
       "285  58.0  1.0  4.0     114.0  318.0  0.0      1.0    140.0    0.0      4.4   \n",
       "286  58.0  0.0  4.0     170.0  225.0  1.0      2.0    146.0    1.0      2.8   \n",
       "287  58.0  1.0  2.0     125.0  220.0  0.0      0.0    144.0    0.0      0.4   \n",
       "288  56.0  1.0  2.0     130.0  221.0  0.0      2.0    163.0    0.0      0.0   \n",
       "289  56.0  1.0  2.0     120.0  240.0  0.0      0.0    169.0    0.0      0.0   \n",
       "290  67.0  1.0  3.0     152.0  212.0  0.0      2.0    150.0    0.0      0.8   \n",
       "291  55.0  0.0  2.0     132.0  342.0  0.0      0.0    166.0    0.0      1.2   \n",
       "292  44.0  1.0  4.0     120.0  169.0  0.0      0.0    144.0    1.0      2.8   \n",
       "293  63.0  1.0  4.0     140.0  187.0  0.0      2.0    144.0    1.0      4.0   \n",
       "294  63.0  0.0  4.0     124.0  197.0  0.0      0.0    136.0    1.0      0.0   \n",
       "295  41.0  1.0  2.0     120.0  157.0  0.0      0.0    182.0    0.0      0.0   \n",
       "296  59.0  1.0  4.0     164.0  176.0  1.0      2.0     90.0    0.0      1.0   \n",
       "297  57.0  0.0  4.0     140.0  241.0  0.0      0.0    123.0    1.0      0.2   \n",
       "298  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
       "299  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "300  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "301  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
       "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  class  \n",
       "280    2.0  1.0  7.0      2  \n",
       "281    1.0  0.0  3.0      0  \n",
       "282    2.0  1.0  7.0      3  \n",
       "283    1.0  0.0  3.0      0  \n",
       "284    1.0  1.0  7.0      2  \n",
       "285    3.0  3.0  6.0      4  \n",
       "286    2.0  2.0  6.0      2  \n",
       "287    2.0  NaN  7.0      0  \n",
       "288    1.0  0.0  7.0      0  \n",
       "289    3.0  0.0  3.0      0  \n",
       "290    2.0  0.0  7.0      1  \n",
       "291    1.0  0.0  3.0      0  \n",
       "292    3.0  0.0  6.0      2  \n",
       "293    1.0  2.0  7.0      2  \n",
       "294    2.0  0.0  3.0      1  \n",
       "295    1.0  0.0  3.0      0  \n",
       "296    2.0  2.0  6.0      3  \n",
       "297    2.0  0.0  7.0      1  \n",
       "298    2.0  0.0  7.0      1  \n",
       "299    2.0  2.0  7.0      2  \n",
       "300    2.0  1.0  7.0      3  \n",
       "301    2.0  1.0  3.0      1  \n",
       "302    1.0  NaN  3.0      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove missing data (indicated with a \"?\")\n",
    "data = cleveland[~cleveland.isin(['?'])]\n",
    "data.loc[280:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "280  57.0  1.0  4.0     110.0  335.0  0.0      0.0    143.0    1.0      3.0   \n",
       "281  47.0  1.0  3.0     130.0  253.0  0.0      0.0    179.0    0.0      0.0   \n",
       "282  55.0  0.0  4.0     128.0  205.0  0.0      1.0    130.0    1.0      2.0   \n",
       "283  35.0  1.0  2.0     122.0  192.0  0.0      0.0    174.0    0.0      0.0   \n",
       "284  61.0  1.0  4.0     148.0  203.0  0.0      0.0    161.0    0.0      0.0   \n",
       "285  58.0  1.0  4.0     114.0  318.0  0.0      1.0    140.0    0.0      4.4   \n",
       "286  58.0  0.0  4.0     170.0  225.0  1.0      2.0    146.0    1.0      2.8   \n",
       "288  56.0  1.0  2.0     130.0  221.0  0.0      2.0    163.0    0.0      0.0   \n",
       "289  56.0  1.0  2.0     120.0  240.0  0.0      0.0    169.0    0.0      0.0   \n",
       "290  67.0  1.0  3.0     152.0  212.0  0.0      2.0    150.0    0.0      0.8   \n",
       "291  55.0  0.0  2.0     132.0  342.0  0.0      0.0    166.0    0.0      1.2   \n",
       "292  44.0  1.0  4.0     120.0  169.0  0.0      0.0    144.0    1.0      2.8   \n",
       "293  63.0  1.0  4.0     140.0  187.0  0.0      2.0    144.0    1.0      4.0   \n",
       "294  63.0  0.0  4.0     124.0  197.0  0.0      0.0    136.0    1.0      0.0   \n",
       "295  41.0  1.0  2.0     120.0  157.0  0.0      0.0    182.0    0.0      0.0   \n",
       "296  59.0  1.0  4.0     164.0  176.0  1.0      2.0     90.0    0.0      1.0   \n",
       "297  57.0  0.0  4.0     140.0  241.0  0.0      0.0    123.0    1.0      0.2   \n",
       "298  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
       "299  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "300  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "301  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  class  \n",
       "280    2.0  1.0  7.0      2  \n",
       "281    1.0  0.0  3.0      0  \n",
       "282    2.0  1.0  7.0      3  \n",
       "283    1.0  0.0  3.0      0  \n",
       "284    1.0  1.0  7.0      2  \n",
       "285    3.0  3.0  6.0      4  \n",
       "286    2.0  2.0  6.0      2  \n",
       "288    1.0  0.0  7.0      0  \n",
       "289    3.0  0.0  3.0      0  \n",
       "290    2.0  0.0  7.0      1  \n",
       "291    1.0  0.0  3.0      0  \n",
       "292    3.0  0.0  6.0      2  \n",
       "293    1.0  2.0  7.0      2  \n",
       "294    2.0  0.0  3.0      1  \n",
       "295    1.0  0.0  3.0      0  \n",
       "296    2.0  2.0  6.0      3  \n",
       "297    2.0  0.0  7.0      1  \n",
       "298    2.0  0.0  7.0      1  \n",
       "299    2.0  2.0  7.0      2  \n",
       "300    2.0  1.0  7.0      3  \n",
       "301    2.0  1.0  3.0      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with NaN values from DataFrame\n",
    "data = data.dropna(axis=0)\n",
    "data.loc[280:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformacion de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297, 14)\n",
      "age         float64\n",
      "sex         float64\n",
      "cp          float64\n",
      "trestbps    float64\n",
      "chol        float64\n",
      "fbs         float64\n",
      "restecg     float64\n",
      "thalach     float64\n",
      "exang       float64\n",
      "oldpeak     float64\n",
      "slope       float64\n",
      "ca           object\n",
      "thal         object\n",
      "class         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print the shape and data type of the dataframe\n",
    "print (data.shape)\n",
    "print (data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         float64\n",
       "sex         float64\n",
       "cp          float64\n",
       "trestbps    float64\n",
       "chol        float64\n",
       "fbs         float64\n",
       "restecg     float64\n",
       "thalach     float64\n",
       "exang       float64\n",
       "oldpeak     float64\n",
       "slope       float64\n",
       "ca          float64\n",
       "thal        float64\n",
       "class         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform data to numeric to enable further analysis\n",
    "data = data.apply(pd.to_numeric)\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.542088</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>3.158249</td>\n",
       "      <td>131.693603</td>\n",
       "      <td>247.350168</td>\n",
       "      <td>0.144781</td>\n",
       "      <td>0.996633</td>\n",
       "      <td>149.599327</td>\n",
       "      <td>0.326599</td>\n",
       "      <td>1.055556</td>\n",
       "      <td>1.602694</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>4.730640</td>\n",
       "      <td>0.946128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.049736</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.964859</td>\n",
       "      <td>17.762806</td>\n",
       "      <td>51.997583</td>\n",
       "      <td>0.352474</td>\n",
       "      <td>0.994914</td>\n",
       "      <td>22.941562</td>\n",
       "      <td>0.469761</td>\n",
       "      <td>1.166123</td>\n",
       "      <td>0.618187</td>\n",
       "      <td>0.938965</td>\n",
       "      <td>1.938629</td>\n",
       "      <td>1.234551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  297.000000  297.000000  297.000000  297.000000  297.000000  297.000000   \n",
       "mean    54.542088    0.676768    3.158249  131.693603  247.350168    0.144781   \n",
       "std      9.049736    0.468500    0.964859   17.762806   51.997583    0.352474   \n",
       "min     29.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.000000    0.000000    3.000000  120.000000  211.000000    0.000000   \n",
       "50%     56.000000    1.000000    3.000000  130.000000  243.000000    0.000000   \n",
       "75%     61.000000    1.000000    4.000000  140.000000  276.000000    0.000000   \n",
       "max     77.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  297.000000  297.000000  297.000000  297.000000  297.000000  297.000000   \n",
       "mean     0.996633  149.599327    0.326599    1.055556    1.602694    0.676768   \n",
       "std      0.994914   22.941562    0.469761    1.166123    0.618187    0.938965   \n",
       "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "25%      0.000000  133.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    2.000000    0.000000   \n",
       "75%      2.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    3.000000    3.000000   \n",
       "\n",
       "             thal       class  \n",
       "count  297.000000  297.000000  \n",
       "mean     4.730640    0.946128  \n",
       "std      1.938629    1.234551  \n",
       "min      3.000000    0.000000  \n",
       "25%      3.000000    0.000000  \n",
       "50%      3.000000    0.000000  \n",
       "75%      7.000000    2.000000  \n",
       "max      7.000000    4.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print data characteristics, usings pandas built-in describe() function\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imprimimos un histograma por cada variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot histograms for each variable\n",
    "data.hist(figsize = (12, 12))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creacion de los datos de entrenamiento y prueba\n",
    "\n",
    "Ahora que hemos preprocesado los datos adecuadamente, podemos dividirlos en conjuntos de datos de capacitación y pruebas. Utilizaremos la función train_test_split () de Sklearn para generar un conjunto de datos de entrenamiento (80 por ciento de los datos totales) y un conjunto de datos de prueba (20 por ciento de los datos totales).\n",
    "\n",
    "Además, los valores de clase en este conjunto de datos contienen múltiples tipos de enfermedad cardíaca con valores que van desde 0 (saludable) a 4 (enfermedad cardíaca grave). En consecuencia, necesitaremos convertir nuestros datos de clase en etiquetas categóricas. Por ejemplo, la etiqueta 2 se convertirá en [0, 0, 1, 0, 0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and Y datasets for training\n",
    "from sklearn import model_selection\n",
    "\n",
    "X = np.array(data.drop(['class'], 1))\n",
    "y = np.array(data['class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237, 5)\n",
      "[[0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# convert the data to categorical labels\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(y_train, num_classes=None)\n",
    "Y_test = to_categorical(y_test, num_classes=None)\n",
    "print (Y_train.shape)\n",
    "print (Y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construccion y entrenamiento\n",
    "\n",
    "Ahora que tenemos nuestros datos completamente procesados y divididos en conjuntos de datos de entrenamiento y prueba, podemos comenzar a construir una red neuronal para resolver este problema de clasificación. Usando keras, definiremos una red neuronal simple con una capa oculta. Dado que este es un problema de clasificación categórica, usaremos una función de activación softmax en la capa final de nuestra red y una pérdida de crossentropía categórica durante nuestra fase de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 112       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 25        \n",
      "=================================================================\n",
      "Total params: 173\n",
      "Trainable params: 173\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# define a function to build the keras model\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/echartea/python/entronoVirtual/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "237/237 [==============================] - 0s 803us/step - loss: 1.8259 - accuracy: 0.3207\n",
      "Epoch 2/100\n",
      "237/237 [==============================] - 0s 188us/step - loss: 1.5917 - accuracy: 0.5316\n",
      "Epoch 3/100\n",
      "237/237 [==============================] - 0s 180us/step - loss: 1.5802 - accuracy: 0.5316\n",
      "Epoch 4/100\n",
      "237/237 [==============================] - 0s 201us/step - loss: 1.5686 - accuracy: 0.5316\n",
      "Epoch 5/100\n",
      "237/237 [==============================] - 0s 179us/step - loss: 1.5575 - accuracy: 0.5316\n",
      "Epoch 6/100\n",
      "237/237 [==============================] - 0s 175us/step - loss: 1.5465 - accuracy: 0.5316\n",
      "Epoch 7/100\n",
      "237/237 [==============================] - 0s 161us/step - loss: 1.5360 - accuracy: 0.5316\n",
      "Epoch 8/100\n",
      "237/237 [==============================] - 0s 159us/step - loss: 1.5256 - accuracy: 0.5316\n",
      "Epoch 9/100\n",
      "237/237 [==============================] - 0s 118us/step - loss: 1.5154 - accuracy: 0.5316\n",
      "Epoch 10/100\n",
      "237/237 [==============================] - 0s 182us/step - loss: 1.5058 - accuracy: 0.5316\n",
      "Epoch 11/100\n",
      "237/237 [==============================] - 0s 181us/step - loss: 1.4966 - accuracy: 0.5316\n",
      "Epoch 12/100\n",
      "237/237 [==============================] - 0s 216us/step - loss: 1.4877 - accuracy: 0.5316\n",
      "Epoch 13/100\n",
      "237/237 [==============================] - 0s 246us/step - loss: 1.4790 - accuracy: 0.5316\n",
      "Epoch 14/100\n",
      "237/237 [==============================] - 0s 188us/step - loss: 1.4705 - accuracy: 0.5316\n",
      "Epoch 15/100\n",
      "237/237 [==============================] - 0s 203us/step - loss: 1.4626 - accuracy: 0.5316\n",
      "Epoch 16/100\n",
      "237/237 [==============================] - 0s 184us/step - loss: 1.4551 - accuracy: 0.5316\n",
      "Epoch 17/100\n",
      "237/237 [==============================] - 0s 181us/step - loss: 1.4474 - accuracy: 0.5316\n",
      "Epoch 18/100\n",
      "237/237 [==============================] - 0s 179us/step - loss: 1.4406 - accuracy: 0.5316\n",
      "Epoch 19/100\n",
      "237/237 [==============================] - 0s 192us/step - loss: 1.4334 - accuracy: 0.5316\n",
      "Epoch 20/100\n",
      "237/237 [==============================] - 0s 200us/step - loss: 1.4271 - accuracy: 0.5316\n",
      "Epoch 21/100\n",
      "237/237 [==============================] - 0s 195us/step - loss: 1.4208 - accuracy: 0.5316\n",
      "Epoch 22/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 1.4148 - accuracy: 0.5316\n",
      "Epoch 23/100\n",
      "237/237 [==============================] - 0s 168us/step - loss: 1.4088 - accuracy: 0.5316\n",
      "Epoch 24/100\n",
      "237/237 [==============================] - 0s 161us/step - loss: 1.4036 - accuracy: 0.5316\n",
      "Epoch 25/100\n",
      "237/237 [==============================] - 0s 166us/step - loss: 1.3981 - accuracy: 0.5316\n",
      "Epoch 26/100\n",
      "237/237 [==============================] - 0s 177us/step - loss: 1.3933 - accuracy: 0.5316\n",
      "Epoch 27/100\n",
      "237/237 [==============================] - 0s 200us/step - loss: 1.3884 - accuracy: 0.5316\n",
      "Epoch 28/100\n",
      "237/237 [==============================] - 0s 194us/step - loss: 1.3838 - accuracy: 0.5316\n",
      "Epoch 29/100\n",
      "237/237 [==============================] - 0s 172us/step - loss: 1.3794 - accuracy: 0.5316\n",
      "Epoch 30/100\n",
      "237/237 [==============================] - 0s 168us/step - loss: 1.3753 - accuracy: 0.5316\n",
      "Epoch 31/100\n",
      "237/237 [==============================] - 0s 201us/step - loss: 1.3712 - accuracy: 0.5316\n",
      "Epoch 32/100\n",
      "237/237 [==============================] - 0s 189us/step - loss: 1.3674 - accuracy: 0.5316\n",
      "Epoch 33/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 1.3638 - accuracy: 0.5316\n",
      "Epoch 34/100\n",
      "237/237 [==============================] - 0s 232us/step - loss: 1.3604 - accuracy: 0.5316\n",
      "Epoch 35/100\n",
      "237/237 [==============================] - 0s 197us/step - loss: 1.3571 - accuracy: 0.5316\n",
      "Epoch 36/100\n",
      "237/237 [==============================] - 0s 218us/step - loss: 1.3541 - accuracy: 0.5316\n",
      "Epoch 37/100\n",
      "237/237 [==============================] - 0s 240us/step - loss: 1.3511 - accuracy: 0.5316\n",
      "Epoch 38/100\n",
      "237/237 [==============================] - 0s 213us/step - loss: 1.3484 - accuracy: 0.5316\n",
      "Epoch 39/100\n",
      "237/237 [==============================] - 0s 203us/step - loss: 1.3457 - accuracy: 0.5316\n",
      "Epoch 40/100\n",
      "237/237 [==============================] - 0s 222us/step - loss: 1.3432 - accuracy: 0.5316\n",
      "Epoch 41/100\n",
      "237/237 [==============================] - 0s 212us/step - loss: 1.3408 - accuracy: 0.5316\n",
      "Epoch 42/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.3387 - accuracy: 0.5316\n",
      "Epoch 43/100\n",
      "237/237 [==============================] - 0s 223us/step - loss: 1.3365 - accuracy: 0.5316\n",
      "Epoch 44/100\n",
      "237/237 [==============================] - 0s 177us/step - loss: 1.3344 - accuracy: 0.5316\n",
      "Epoch 45/100\n",
      "237/237 [==============================] - 0s 215us/step - loss: 1.3327 - accuracy: 0.5316\n",
      "Epoch 46/100\n",
      "237/237 [==============================] - 0s 230us/step - loss: 1.3308 - accuracy: 0.5316\n",
      "Epoch 47/100\n",
      "237/237 [==============================] - 0s 227us/step - loss: 1.3292 - accuracy: 0.5316\n",
      "Epoch 48/100\n",
      "237/237 [==============================] - 0s 208us/step - loss: 1.3277 - accuracy: 0.5316\n",
      "Epoch 49/100\n",
      "237/237 [==============================] - 0s 181us/step - loss: 1.3260 - accuracy: 0.5316\n",
      "Epoch 50/100\n",
      "237/237 [==============================] - 0s 211us/step - loss: 1.3247 - accuracy: 0.5316\n",
      "Epoch 51/100\n",
      "237/237 [==============================] - 0s 166us/step - loss: 1.3232 - accuracy: 0.5316\n",
      "Epoch 52/100\n",
      "237/237 [==============================] - 0s 180us/step - loss: 1.3219 - accuracy: 0.5316\n",
      "Epoch 53/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.3208 - accuracy: 0.5316\n",
      "Epoch 54/100\n",
      "237/237 [==============================] - 0s 168us/step - loss: 1.3196 - accuracy: 0.5316\n",
      "Epoch 55/100\n",
      "237/237 [==============================] - 0s 143us/step - loss: 1.3186 - accuracy: 0.5316\n",
      "Epoch 56/100\n",
      "237/237 [==============================] - 0s 157us/step - loss: 1.3175 - accuracy: 0.5316\n",
      "Epoch 57/100\n",
      "237/237 [==============================] - 0s 144us/step - loss: 1.3165 - accuracy: 0.5316\n",
      "Epoch 58/100\n",
      "237/237 [==============================] - 0s 172us/step - loss: 1.3156 - accuracy: 0.5316\n",
      "Epoch 59/100\n",
      "237/237 [==============================] - 0s 139us/step - loss: 1.3147 - accuracy: 0.5316\n",
      "Epoch 60/100\n",
      "237/237 [==============================] - 0s 181us/step - loss: 1.3139 - accuracy: 0.5316\n",
      "Epoch 61/100\n",
      "237/237 [==============================] - 0s 150us/step - loss: 1.3131 - accuracy: 0.5316\n",
      "Epoch 62/100\n",
      "237/237 [==============================] - 0s 177us/step - loss: 1.3124 - accuracy: 0.5316\n",
      "Epoch 63/100\n",
      "237/237 [==============================] - 0s 173us/step - loss: 1.3119 - accuracy: 0.5316\n",
      "Epoch 64/100\n",
      "237/237 [==============================] - 0s 168us/step - loss: 1.3111 - accuracy: 0.5316\n",
      "Epoch 65/100\n",
      "237/237 [==============================] - 0s 182us/step - loss: 1.3104 - accuracy: 0.5316\n",
      "Epoch 66/100\n",
      "237/237 [==============================] - 0s 160us/step - loss: 1.3099 - accuracy: 0.5316\n",
      "Epoch 67/100\n",
      "237/237 [==============================] - 0s 172us/step - loss: 1.3094 - accuracy: 0.5316\n",
      "Epoch 68/100\n",
      "237/237 [==============================] - 0s 163us/step - loss: 1.3088 - accuracy: 0.5316\n",
      "Epoch 69/100\n",
      "237/237 [==============================] - 0s 162us/step - loss: 1.3085 - accuracy: 0.5316\n",
      "Epoch 70/100\n",
      "237/237 [==============================] - 0s 153us/step - loss: 1.3079 - accuracy: 0.5316\n",
      "Epoch 71/100\n",
      "237/237 [==============================] - 0s 166us/step - loss: 1.3074 - accuracy: 0.5316\n",
      "Epoch 72/100\n",
      "237/237 [==============================] - 0s 168us/step - loss: 1.3070 - accuracy: 0.5316\n",
      "Epoch 73/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 1.3066 - accuracy: 0.5316\n",
      "Epoch 74/100\n",
      "237/237 [==============================] - 0s 166us/step - loss: 1.3063 - accuracy: 0.5316\n",
      "Epoch 75/100\n",
      "237/237 [==============================] - 0s 164us/step - loss: 1.3058 - accuracy: 0.5316\n",
      "Epoch 76/100\n",
      "237/237 [==============================] - 0s 150us/step - loss: 1.3056 - accuracy: 0.5316\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/237 [==============================] - 0s 153us/step - loss: 1.3052 - accuracy: 0.5316\n",
      "Epoch 78/100\n",
      "237/237 [==============================] - 0s 157us/step - loss: 1.3050 - accuracy: 0.5316\n",
      "Epoch 79/100\n",
      "237/237 [==============================] - 0s 164us/step - loss: 1.3047 - accuracy: 0.5316\n",
      "Epoch 80/100\n",
      "237/237 [==============================] - 0s 148us/step - loss: 1.3044 - accuracy: 0.5316\n",
      "Epoch 81/100\n",
      "237/237 [==============================] - 0s 167us/step - loss: 1.3042 - accuracy: 0.5316\n",
      "Epoch 82/100\n",
      "237/237 [==============================] - 0s 162us/step - loss: 1.3040 - accuracy: 0.5316\n",
      "Epoch 83/100\n",
      "237/237 [==============================] - 0s 149us/step - loss: 1.3037 - accuracy: 0.5316\n",
      "Epoch 84/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 1.3036 - accuracy: 0.5316\n",
      "Epoch 85/100\n",
      "237/237 [==============================] - 0s 167us/step - loss: 1.3033 - accuracy: 0.5316\n",
      "Epoch 86/100\n",
      "237/237 [==============================] - 0s 154us/step - loss: 1.3031 - accuracy: 0.5316\n",
      "Epoch 87/100\n",
      "237/237 [==============================] - 0s 165us/step - loss: 1.3029 - accuracy: 0.5316\n",
      "Epoch 88/100\n",
      "237/237 [==============================] - ETA: 0s - loss: 1.7271 - accuracy: 0.20 - 0s 155us/step - loss: 1.3028 - accuracy: 0.5316\n",
      "Epoch 89/100\n",
      "237/237 [==============================] - 0s 160us/step - loss: 1.3026 - accuracy: 0.5316\n",
      "Epoch 90/100\n",
      "237/237 [==============================] - 0s 153us/step - loss: 1.3024 - accuracy: 0.5316\n",
      "Epoch 91/100\n",
      "237/237 [==============================] - 0s 155us/step - loss: 1.3023 - accuracy: 0.5316\n",
      "Epoch 92/100\n",
      "237/237 [==============================] - 0s 165us/step - loss: 1.3021 - accuracy: 0.5316\n",
      "Epoch 93/100\n",
      "237/237 [==============================] - 0s 147us/step - loss: 1.3023 - accuracy: 0.5316\n",
      "Epoch 94/100\n",
      "237/237 [==============================] - 0s 180us/step - loss: 1.3018 - accuracy: 0.5316\n",
      "Epoch 95/100\n",
      "237/237 [==============================] - 0s 145us/step - loss: 1.3017 - accuracy: 0.5316\n",
      "Epoch 96/100\n",
      "237/237 [==============================] - 0s 156us/step - loss: 1.3016 - accuracy: 0.5316\n",
      "Epoch 97/100\n",
      "237/237 [==============================] - 0s 156us/step - loss: 1.3015 - accuracy: 0.5316\n",
      "Epoch 98/100\n",
      "237/237 [==============================] - 0s 150us/step - loss: 1.3014 - accuracy: 0.5316\n",
      "Epoch 99/100\n",
      "237/237 [==============================] - 0s 163us/step - loss: 1.3012 - accuracy: 0.5316\n",
      "Epoch 100/100\n",
      "237/237 [==============================] - 0s 162us/step - loss: 1.3011 - accuracy: 0.5316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f02df2bf8d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model to the training data\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=10, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejora de resultados\n",
    "\n",
    "Aunque logramos resultados prometedores, todavía tenemos un error bastante grande. Esto podría deberse a que es muy difícil distinguir entre los diferentes niveles de gravedad de la enfermedad cardíaca (clases 1 a 4). Simplifiquemos el problema convirtiendo los datos en un problema de clasificación binaria: enfermedad cardíaca o ninguna enfermedad cardíaca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# convert into binary classification problem - heart disease or no heart disease\n",
    "Y_train_binary = y_train.copy()\n",
    "Y_test_binary = y_test.copy()\n",
    "\n",
    "Y_train_binary[Y_train_binary > 0] = 1\n",
    "Y_test_binary[Y_test_binary > 0] = 1\n",
    "\n",
    "print (Y_train_binary[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/echartea/python/entronoVirtual/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 8)                 112       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 153\n",
      "Trainable params: 153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define a new keras model for binary classification\n",
    "def create_binary_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "binary_model = create_binary_model()\n",
    "\n",
    "print(binary_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "237/237 [==============================] - 0s 678us/step - loss: 0.7036 - accuracy: 0.4937\n",
      "Epoch 2/100\n",
      "237/237 [==============================] - 0s 189us/step - loss: 0.6874 - accuracy: 0.5992\n",
      "Epoch 3/100\n",
      "237/237 [==============================] - 0s 194us/step - loss: 0.6844 - accuracy: 0.5949\n",
      "Epoch 4/100\n",
      "237/237 [==============================] - 0s 233us/step - loss: 0.6810 - accuracy: 0.6076\n",
      "Epoch 5/100\n",
      "237/237 [==============================] - 0s 223us/step - loss: 0.6771 - accuracy: 0.6203\n",
      "Epoch 6/100\n",
      "237/237 [==============================] - 0s 187us/step - loss: 0.6740 - accuracy: 0.6034\n",
      "Epoch 7/100\n",
      "237/237 [==============================] - 0s 223us/step - loss: 0.6699 - accuracy: 0.6709\n",
      "Epoch 8/100\n",
      "237/237 [==============================] - 0s 207us/step - loss: 0.6664 - accuracy: 0.6456\n",
      "Epoch 9/100\n",
      "237/237 [==============================] - 0s 210us/step - loss: 0.6569 - accuracy: 0.6835\n",
      "Epoch 10/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.6524 - accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "237/237 [==============================] - 0s 206us/step - loss: 0.6454 - accuracy: 0.7004\n",
      "Epoch 12/100\n",
      "237/237 [==============================] - 0s 194us/step - loss: 0.6377 - accuracy: 0.7046\n",
      "Epoch 13/100\n",
      "237/237 [==============================] - 0s 175us/step - loss: 0.6312 - accuracy: 0.6835\n",
      "Epoch 14/100\n",
      "237/237 [==============================] - 0s 197us/step - loss: 0.6278 - accuracy: 0.6751\n",
      "Epoch 15/100\n",
      "237/237 [==============================] - 0s 200us/step - loss: 0.6183 - accuracy: 0.7089\n",
      "Epoch 16/100\n",
      "237/237 [==============================] - 0s 197us/step - loss: 0.6068 - accuracy: 0.7342\n",
      "Epoch 17/100\n",
      "237/237 [==============================] - 0s 192us/step - loss: 0.6116 - accuracy: 0.7300\n",
      "Epoch 18/100\n",
      "237/237 [==============================] - 0s 208us/step - loss: 0.5977 - accuracy: 0.7637\n",
      "Epoch 19/100\n",
      "237/237 [==============================] - 0s 199us/step - loss: 0.6055 - accuracy: 0.7426\n",
      "Epoch 20/100\n",
      "237/237 [==============================] - 0s 218us/step - loss: 0.5918 - accuracy: 0.7468\n",
      "Epoch 21/100\n",
      "237/237 [==============================] - 0s 207us/step - loss: 0.5828 - accuracy: 0.7511\n",
      "Epoch 22/100\n",
      "237/237 [==============================] - 0s 187us/step - loss: 0.5778 - accuracy: 0.7806\n",
      "Epoch 23/100\n",
      "237/237 [==============================] - 0s 210us/step - loss: 0.5852 - accuracy: 0.7215\n",
      "Epoch 24/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.5659 - accuracy: 0.7637\n",
      "Epoch 25/100\n",
      "237/237 [==============================] - 0s 218us/step - loss: 0.5712 - accuracy: 0.7468\n",
      "Epoch 26/100\n",
      "237/237 [==============================] - 0s 197us/step - loss: 0.5582 - accuracy: 0.7764\n",
      "Epoch 27/100\n",
      "237/237 [==============================] - 0s 218us/step - loss: 0.5547 - accuracy: 0.7722\n",
      "Epoch 28/100\n",
      "237/237 [==============================] - 0s 244us/step - loss: 0.5565 - accuracy: 0.7679\n",
      "Epoch 29/100\n",
      "237/237 [==============================] - 0s 200us/step - loss: 0.5463 - accuracy: 0.7848\n",
      "Epoch 30/100\n",
      "237/237 [==============================] - 0s 216us/step - loss: 0.5425 - accuracy: 0.7806\n",
      "Epoch 31/100\n",
      "237/237 [==============================] - 0s 194us/step - loss: 0.5450 - accuracy: 0.7848\n",
      "Epoch 32/100\n",
      "237/237 [==============================] - 0s 211us/step - loss: 0.5385 - accuracy: 0.8017\n",
      "Epoch 33/100\n",
      "237/237 [==============================] - 0s 182us/step - loss: 0.5308 - accuracy: 0.7975\n",
      "Epoch 34/100\n",
      "237/237 [==============================] - 0s 201us/step - loss: 0.5276 - accuracy: 0.7975\n",
      "Epoch 35/100\n",
      "237/237 [==============================] - 0s 213us/step - loss: 0.5440 - accuracy: 0.7553\n",
      "Epoch 36/100\n",
      "237/237 [==============================] - 0s 198us/step - loss: 0.5302 - accuracy: 0.8017\n",
      "Epoch 37/100\n",
      "237/237 [==============================] - 0s 211us/step - loss: 0.5185 - accuracy: 0.7848\n",
      "Epoch 38/100\n",
      "237/237 [==============================] - 0s 178us/step - loss: 0.5252 - accuracy: 0.7848\n",
      "Epoch 39/100\n",
      "237/237 [==============================] - 0s 214us/step - loss: 0.5291 - accuracy: 0.7848\n",
      "Epoch 40/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.5219 - accuracy: 0.7890\n",
      "Epoch 41/100\n",
      "237/237 [==============================] - 0s 211us/step - loss: 0.5024 - accuracy: 0.8143\n",
      "Epoch 42/100\n",
      "237/237 [==============================] - 0s 218us/step - loss: 0.5013 - accuracy: 0.8228\n",
      "Epoch 43/100\n",
      "237/237 [==============================] - 0s 293us/step - loss: 0.4980 - accuracy: 0.8143\n",
      "Epoch 44/100\n",
      "237/237 [==============================] - 0s 257us/step - loss: 0.4968 - accuracy: 0.8101\n",
      "Epoch 45/100\n",
      "237/237 [==============================] - 0s 223us/step - loss: 0.4998 - accuracy: 0.8059\n",
      "Epoch 46/100\n",
      "237/237 [==============================] - 0s 264us/step - loss: 0.4917 - accuracy: 0.8270\n",
      "Epoch 47/100\n",
      "237/237 [==============================] - 0s 244us/step - loss: 0.4936 - accuracy: 0.8143\n",
      "Epoch 48/100\n",
      "237/237 [==============================] - 0s 223us/step - loss: 0.4909 - accuracy: 0.8228\n",
      "Epoch 49/100\n",
      "237/237 [==============================] - 0s 178us/step - loss: 0.4926 - accuracy: 0.8017\n",
      "Epoch 50/100\n",
      "237/237 [==============================] - 0s 203us/step - loss: 0.4914 - accuracy: 0.8228\n",
      "Epoch 51/100\n",
      "237/237 [==============================] - 0s 234us/step - loss: 0.4795 - accuracy: 0.8312\n",
      "Epoch 52/100\n",
      "237/237 [==============================] - 0s 294us/step - loss: 0.4783 - accuracy: 0.8270\n",
      "Epoch 53/100\n",
      "237/237 [==============================] - 0s 275us/step - loss: 0.4770 - accuracy: 0.8143\n",
      "Epoch 54/100\n",
      "237/237 [==============================] - 0s 267us/step - loss: 0.4746 - accuracy: 0.8101\n",
      "Epoch 55/100\n",
      "237/237 [==============================] - 0s 173us/step - loss: 0.4737 - accuracy: 0.8312\n",
      "Epoch 56/100\n",
      "237/237 [==============================] - 0s 183us/step - loss: 0.4759 - accuracy: 0.8101\n",
      "Epoch 57/100\n",
      "237/237 [==============================] - 0s 193us/step - loss: 0.5022 - accuracy: 0.7806\n",
      "Epoch 58/100\n",
      "237/237 [==============================] - 0s 200us/step - loss: 0.4698 - accuracy: 0.8270\n",
      "Epoch 59/100\n",
      "237/237 [==============================] - 0s 183us/step - loss: 0.4659 - accuracy: 0.8186\n",
      "Epoch 60/100\n",
      "237/237 [==============================] - 0s 172us/step - loss: 0.4701 - accuracy: 0.8143\n",
      "Epoch 61/100\n",
      "237/237 [==============================] - 0s 193us/step - loss: 0.4634 - accuracy: 0.8143\n",
      "Epoch 62/100\n",
      "237/237 [==============================] - 0s 200us/step - loss: 0.4641 - accuracy: 0.8186\n",
      "Epoch 63/100\n",
      "237/237 [==============================] - 0s 182us/step - loss: 0.4602 - accuracy: 0.8101\n",
      "Epoch 64/100\n",
      "237/237 [==============================] - 0s 189us/step - loss: 0.4536 - accuracy: 0.8354\n",
      "Epoch 65/100\n",
      "237/237 [==============================] - 0s 184us/step - loss: 0.4759 - accuracy: 0.8059\n",
      "Epoch 66/100\n",
      "237/237 [==============================] - 0s 191us/step - loss: 0.4714 - accuracy: 0.8186\n",
      "Epoch 67/100\n",
      "237/237 [==============================] - 0s 173us/step - loss: 0.4534 - accuracy: 0.8312\n",
      "Epoch 68/100\n",
      "237/237 [==============================] - 0s 198us/step - loss: 0.4529 - accuracy: 0.8312\n",
      "Epoch 69/100\n",
      "237/237 [==============================] - 0s 217us/step - loss: 0.4472 - accuracy: 0.8270\n",
      "Epoch 70/100\n",
      "237/237 [==============================] - 0s 212us/step - loss: 0.4637 - accuracy: 0.7975\n",
      "Epoch 71/100\n",
      "237/237 [==============================] - 0s 196us/step - loss: 0.4576 - accuracy: 0.8059\n",
      "Epoch 72/100\n",
      "237/237 [==============================] - 0s 196us/step - loss: 0.4471 - accuracy: 0.8397\n",
      "Epoch 73/100\n",
      "237/237 [==============================] - 0s 212us/step - loss: 0.4479 - accuracy: 0.8312\n",
      "Epoch 74/100\n",
      "237/237 [==============================] - 0s 197us/step - loss: 0.4486 - accuracy: 0.8228\n",
      "Epoch 75/100\n",
      "237/237 [==============================] - 0s 197us/step - loss: 0.4432 - accuracy: 0.8312\n",
      "Epoch 76/100\n",
      "237/237 [==============================] - 0s 200us/step - loss: 0.4666 - accuracy: 0.8228\n",
      "Epoch 77/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.4470 - accuracy: 0.8312\n",
      "Epoch 78/100\n",
      "237/237 [==============================] - 0s 173us/step - loss: 0.4361 - accuracy: 0.8186\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/237 [==============================] - 0s 181us/step - loss: 0.4639 - accuracy: 0.8143\n",
      "Epoch 80/100\n",
      "237/237 [==============================] - 0s 166us/step - loss: 0.4765 - accuracy: 0.7975\n",
      "Epoch 81/100\n",
      "237/237 [==============================] - 0s 173us/step - loss: 0.4848 - accuracy: 0.7637\n",
      "Epoch 82/100\n",
      "237/237 [==============================] - 0s 170us/step - loss: 0.4420 - accuracy: 0.8481\n",
      "Epoch 83/100\n",
      "237/237 [==============================] - 0s 187us/step - loss: 0.4357 - accuracy: 0.8312\n",
      "Epoch 84/100\n",
      "237/237 [==============================] - 0s 158us/step - loss: 0.4364 - accuracy: 0.8312\n",
      "Epoch 85/100\n",
      "237/237 [==============================] - 0s 188us/step - loss: 0.4346 - accuracy: 0.8354\n",
      "Epoch 86/100\n",
      "237/237 [==============================] - 0s 185us/step - loss: 0.4355 - accuracy: 0.8354\n",
      "Epoch 87/100\n",
      "237/237 [==============================] - 0s 182us/step - loss: 0.4468 - accuracy: 0.8439\n",
      "Epoch 88/100\n",
      "237/237 [==============================] - 0s 154us/step - loss: 0.4331 - accuracy: 0.8270\n",
      "Epoch 89/100\n",
      "237/237 [==============================] - 0s 167us/step - loss: 0.4320 - accuracy: 0.8312\n",
      "Epoch 90/100\n",
      "237/237 [==============================] - 0s 157us/step - loss: 0.4278 - accuracy: 0.8439\n",
      "Epoch 91/100\n",
      "237/237 [==============================] - 0s 157us/step - loss: 0.4387 - accuracy: 0.8228\n",
      "Epoch 92/100\n",
      "237/237 [==============================] - 0s 147us/step - loss: 0.4478 - accuracy: 0.8143\n",
      "Epoch 93/100\n",
      "237/237 [==============================] - 0s 181us/step - loss: 0.4251 - accuracy: 0.8397\n",
      "Epoch 94/100\n",
      "237/237 [==============================] - 0s 199us/step - loss: 0.4281 - accuracy: 0.8565\n",
      "Epoch 95/100\n",
      "237/237 [==============================] - 0s 184us/step - loss: 0.4302 - accuracy: 0.8397\n",
      "Epoch 96/100\n",
      "237/237 [==============================] - 0s 171us/step - loss: 0.4224 - accuracy: 0.8523\n",
      "Epoch 97/100\n",
      "237/237 [==============================] - 0s 194us/step - loss: 0.4254 - accuracy: 0.8354\n",
      "Epoch 98/100\n",
      "237/237 [==============================] - 0s 190us/step - loss: 0.4280 - accuracy: 0.8397\n",
      "Epoch 99/100\n",
      "237/237 [==============================] - 0s 161us/step - loss: 0.4254 - accuracy: 0.8312\n",
      "Epoch 100/100\n",
      "237/237 [==============================] - 0s 191us/step - loss: 0.4210 - accuracy: 0.8228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f02df118cf8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the binary model on the training data\n",
    "binary_model.fit(X_train, Y_train_binary, epochs=100, batch_size=10, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados\n",
    "\n",
    "Los resultados de precisión que hemos estado viendo son para los datos de entrenamiento, pero ¿qué pasa con el conjunto de datos de prueba? Si nuestros modelos no pueden generalizarse a datos que no se utilizaron para capacitarlos, no proporcionarán ninguna utilidad.\n",
    "\n",
    "Probemos el rendimiento de nuestro modelo categórico y nuestro modelo binario. Para hacer esto, haremos predicciones sobre el conjunto de datos de entrenamiento y calcularemos métricas de rendimiento usando Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Categorical Model\n",
      "0.5666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.72        34\n",
      "           1       0.00      0.00      0.00        12\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.57        60\n",
      "   macro avg       0.11      0.20      0.14        60\n",
      "weighted avg       0.32      0.57      0.41        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echartea/python/entronoVirtual/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# generate classification report using predictions for categorical model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "categorical_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "print('Results for Categorical Model')\n",
    "print(accuracy_score(y_test, categorical_pred))\n",
    "print(classification_report(y_test, categorical_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Binary Model\n",
      "0.8833333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.90        34\n",
      "           1       0.95      0.77      0.85        26\n",
      "\n",
      "    accuracy                           0.88        60\n",
      "   macro avg       0.90      0.87      0.88        60\n",
      "weighted avg       0.89      0.88      0.88        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate classification report using predictions for binary model \n",
    "binary_pred = np.round(binary_model.predict(X_test)).astype(int)\n",
    "\n",
    "print('Results for Binary Model')\n",
    "print(accuracy_score(Y_test_binary, binary_pred))\n",
    "print(classification_report(Y_test_binary, binary_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
